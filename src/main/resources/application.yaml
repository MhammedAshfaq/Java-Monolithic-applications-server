# ===========================================
# Spring Boot Application Configuration
# ===========================================
#
# PROFILES:
#   dev     - Local development (connects to localhost)
#   docker  - Docker environment (connects to container names)
#   prod    - Production settings
#
# LOCAL DEVELOPMENT (Java runs locally, infra in Docker):
#   docker-compose up -d postgres redis pgadmin redis-commander
#   ./mvnw spring-boot:run -Dspring-boot.run.profiles=dev
#   Connects to: localhost:5432, localhost:6379
#
# FULL DOCKER (Everything in Docker):
#   docker-compose up -d
#   Uses profile: docker,dev
#   Connects to: postgres:5432, redis:6379 (container names)
#
# ===========================================

spring:
  main:
    banner-mode: console
  application:
    name: spring-monolith-template
  # Default to dev so localhost:8082 shows the dev tools dashboard.
  # For Docker: SPRING_PROFILES_ACTIVE=docker,dev
  # For Prod:   SPRING_PROFILES_ACTIVE=prod
  profiles:
    active: dev

  # Database configuration
  # Override with environment variables:
  #   DB_HOST=localhost DB_PORT=5432 DB_NAME=mydb DB_USER=user DB_PASSWORD=pass
  datasource:
    url: jdbc:postgresql://${DB_HOST:localhost}:${DB_PORT:5432}/${DB_NAME:java-spring-mololithic}
    username: ${DB_USER:postgres}
    password: ${DB_PASSWORD:postgres}
    driver-class-name: org.postgresql.Driver

    hikari:
      pool-name: HikariPool
      minimum-idle: 5
      maximum-pool-size: 20
      idle-timeout: 30000        # 30 seconds
      max-lifetime: 1800000     # 30 minutes
      connection-timeout: 20000 # 20 seconds
      validation-timeout: 5000

  jpa:
    hibernate:
      ddl-auto: validate
    database-platform: org.hibernate.dialect.PostgreSQLDialect
    show-sql: true

  flyway:
    enabled: true
    baseline-on-migrate: true
    locations: classpath:db/migration
    validate-on-migrate: false
    # Use timestamp-based migrations: 20260205120000__action_name.sql
    sql-migration-prefix: ""
    sql-migration-separator: "__"

  # Quartz Scheduler configuration (DB-backed, production-ready)
  # Quartz stores jobs in PostgreSQL so they survive restarts and support clustering.
  # Spring Boot auto-configures the DataSource and jobStore class — do NOT set them manually.
  quartz:
    job-store-type: jdbc
    jdbc:
      # "never" = Flyway manages the Quartz tables (see migration 20260209180000)
      initialize-schema: never
    # Replace existing jobs on startup (avoids stale/corrupt job data conflicts)
    overwrite-existing-jobs: true
    properties:
      org:
        quartz:
          scheduler:
            instanceName: spring-scheduler
            instanceId: AUTO
          jobStore:
            # Do NOT set 'class' here — Spring Boot handles that.
            # But driverDelegateClass MUST be set for PostgreSQL (BYTEA vs BLOB handling).
            driverDelegateClass: org.quartz.impl.jdbcjobstore.PostgreSQLDelegate
            tablePrefix: QRTZ_
            isClustered: true
            clusterCheckinInterval: 15000
            misfireThreshold: 60000
          threadPool:
            threadCount: 5
            threadPriority: 5

  # Redis configuration
  # Override with environment variables:
  #   REDIS_HOST=localhost REDIS_PORT=6379 REDIS_PASSWORD=yourpass
  data:
    redis:
      host: ${REDIS_HOST:localhost}
      port: ${REDIS_PORT:6379}
      password: ${REDIS_PASSWORD:yourStrongPassword123}
      timeout: 3000ms

  # RabbitMQ configuration
  # Override with environment variables:
  #   RABBITMQ_HOST=localhost RABBITMQ_PORT=5672 RABBITMQ_USER=guest RABBITMQ_PASSWORD=guest
  rabbitmq:
    host: ${RABBITMQ_HOST:localhost}
    port: ${RABBITMQ_PORT:5672}
    username: ${RABBITMQ_USER:guest}
    password: ${RABBITMQ_PASSWORD:guest}
    virtual-host: /
    # Connection settings
    connection-timeout: 10000
    # Publisher confirms — ensures messages reach the broker (production-critical)
    publisher-confirm-type: correlated
    publisher-returns: true
    # Consumer settings
    listener:
      simple:
        # Auto ACK — Spring manages ACK/NACK automatically
        acknowledge-mode: auto
        # Prefetch: how many messages to fetch at once (1 = fair dispatch)
        prefetch: 1
        # Start with 1 consumer, scale up to 3 under load
        concurrency: 1
        max-concurrency: 3
        # Retry: 3 attempts with exponential backoff, then send to DLQ
        retry:
          enabled: true
          initial-interval: 1000    # 1st retry delay: 1s
          max-interval: 10000      # Max delay cap: 10s
          multiplier: 2.0           # Backoff: 1s → 2s → 4s
          max-attempts: 3           # Total attempts before DLQ

  # Multipart (file upload) configuration
  # max-file-size:    Max size of a single uploaded file (default: 1MB).
  #                   Requests with a file exceeding this limit get a MaxUploadSizeExceededException.
  # max-request-size: Max size of the entire multipart request, including all files + form fields (default: 10MB).
  #                   Protects against excessively large payloads consuming server memory/bandwidth.
  servlet:
    multipart:
      enabled: true
      max-file-size: 10MB
      max-request-size: 50MB

# Rate limiting configuration
app:
  # DLQ alert configuration — sends Slack notification when messages fail all retries
  dlq:
    slack:
      enabled: false
      webhook-url: ${DLQ_SLACK_WEBHOOK_URL:}  # Set via env: DLQ_SLACK_WEBHOOK_URL=https://hooks.slack.com/services/XXX/YYY/ZZZ

  rate-limit:
    enabled: true
    # Short-term: Burst protection (100 requests per minute)
    short-term:
      max-requests: 100
      window-seconds: 60
    # Long-term: Overall usage cap (1000 requests per hour)
    long-term:
      max-requests: 1000
      window-seconds: 3600
    # Strict: Sensitive endpoints like login (5 requests per minute)
    strict:
      max-requests: 5
      window-seconds: 60

  # Spring Boot DevTools configuration (automatic restart like nodemon)
  devtools:
    restart:
      enabled: true
      # Additional paths to watch for changes
      additional-paths: src/main/java,src/main/resources
      # Exclude certain paths from triggering restart
      exclude: static/**,public/**,templates/**,META-INF/maven/**,META-INF/resources/**
      # Poll interval for checking changes (in milliseconds)
      poll-interval: 1s
      # Quiet period before restart (in milliseconds)
      quiet-period: 400ms
    livereload:
      enabled: true
      # Port for LiveReload server
      port: 35729

# Server configuration
server:
  address: 0.0.0.0
  port: 8082
  # max-http-header-size: Max allowed size of HTTP request headers (default: 8KB).
  #                      Increase if using large cookies, JWT tokens, or many custom headers.
  #                      Prevents oversized header attacks (HTTP 431 if exceeded).
  max-http-header-size: 16KB
  tomcat:
    # max-swallow-size: Max request body Tomcat will "swallow" (read & discard) after rejecting a request (default: 2MB).
    #                   When a client sends a body larger than allowed but Tomcat has already decided to reject it,
    #                   Tomcat reads up to this amount so the client receives a proper error response
    #                   instead of a broken pipe / connection reset.
    max-swallow-size: 20MB

# ===========================================
# Monitoring & Metrics (Micrometer + Prometheus)
# ===========================================
# Micrometer collects JVM, HTTP, DB, cache metrics automatically.
# Prometheus scrapes /actuator/prometheus every 15s.
# Grafana visualizes the data at http://localhost:3000.
#
# Architecture:
#   App -> Micrometer -> /actuator/prometheus -> Prometheus (scrape) -> Grafana (visualize)
# ===========================================
management:
  endpoints:
    web:
      base-path: /actuator
      exposure:
        # Prometheus endpoint is always exposed (secured by network/firewall in prod, not auth)
        include: health,info,prometheus
  endpoint:
    health:
      show-details: when-authorized
      # Show individual component health (db, redis, diskSpace, etc.)
      show-components: when-authorized
    prometheus:
      enabled: true
  # Metrics configuration
  metrics:
    tags:
      # Add "application" tag to all metrics for multi-app Grafana dashboards
      application: ${spring.application.name}
    distribution:
      # Record percentile histograms for HTTP request durations (p50, p95, p99)
      percentiles-histogram:
        http.server.requests: true
      # Also record explicit percentile values
      percentiles:
        http.server.requests: 0.5, 0.95, 0.99
      # SLA boundaries — counts requests under these thresholds (useful for SLO tracking)
      slo:
        http.server.requests: 50ms, 100ms, 200ms, 500ms, 1s, 5s

# Swagger/OpenAPI configuration
springdoc:
  api-docs:
    path: /v1/api-docs
    enabled: true
  swagger-ui:
    path: /apidocs
    enabled: true
    try-it-out-enabled: true
    operations-sorter: method
    tags-sorter: alpha
    doc-expansion: none
    display-request-duration: true
    show-common-extensions: true
    show-extensions: true
    filter: true
  show-actuator: false
  default-consumes-media-type: application/json
  default-produces-media-type: application/json
  use-management-port: false